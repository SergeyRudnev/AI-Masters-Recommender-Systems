{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54dad7a",
   "metadata": {
    "id": "d54dad7a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#import surprise\n",
    "#import surprise.model_selection \n",
    "#from surprise import SVD\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ecc7b3",
   "metadata": {
    "id": "35ecc7b3"
   },
   "source": [
    "# Загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "r7wJdXpft8tJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7wJdXpft8tJ",
    "outputId": "98a3e011-c9f8-40b6-d960-776baceb06cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594309c",
   "metadata": {
    "id": "8594309c"
   },
   "source": [
    "Отсортируем данные по возрастанию ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be2acb82",
   "metadata": {
    "id": "be2acb82"
   },
   "outputs": [],
   "source": [
    "#dataframe = pd.read_csv('ratings.csv')\n",
    "dataframe = pd.read_csv('/content/drive/MyDrive/AI Masters/ratings.csv')\n",
    "dataframe.sort_values('ts', inplace = True)\n",
    "dataframe.reset_index(drop=True, inplace = True)\n",
    "dataframe.rename(columns = {'user_uid':'user_id', 'element_uid':'item_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20bc8aa",
   "metadata": {
    "id": "b20bc8aa"
   },
   "source": [
    "Воспользуемся LabelEncoder для юзеров и айтемов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c7613c1",
   "metadata": {
    "id": "5c7613c1"
   },
   "outputs": [],
   "source": [
    "u_enc = LabelEncoder()\n",
    "i_enc = LabelEncoder()\n",
    "dataframe['user_id'] = u_enc.fit_transform(dataframe['user_id'])\n",
    "dataframe['item_id'] = i_enc.fit_transform(dataframe['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e599f19b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "e599f19b",
    "outputId": "53c1371b-c9fe-4d0b-e4c2-852a930dc69b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ca3aede1-07df-4118-ac11-2c3a682a6b00\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65882</td>\n",
       "      <td>6586</td>\n",
       "      <td>2</td>\n",
       "      <td>4.173065e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86840</td>\n",
       "      <td>5912</td>\n",
       "      <td>7</td>\n",
       "      <td>4.173078e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62263</td>\n",
       "      <td>2443</td>\n",
       "      <td>8</td>\n",
       "      <td>4.173079e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5710</td>\n",
       "      <td>4521</td>\n",
       "      <td>8</td>\n",
       "      <td>4.173085e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30028</td>\n",
       "      <td>1110</td>\n",
       "      <td>8</td>\n",
       "      <td>4.173086e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca3aede1-07df-4118-ac11-2c3a682a6b00')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ca3aede1-07df-4118-ac11-2c3a682a6b00 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ca3aede1-07df-4118-ac11-2c3a682a6b00');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   user_id  item_id  rating            ts\n",
       "0    65882     6586       2  4.173065e+07\n",
       "1    86840     5912       7  4.173078e+07\n",
       "2    62263     2443       8  4.173079e+07\n",
       "3     5710     4521       8  4.173085e+07\n",
       "4    30028     1110       8  4.173086e+07"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d1d9c",
   "metadata": {
    "id": "457d1d9c"
   },
   "source": [
    "Разобьём данные на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "959e9abb",
   "metadata": {
    "id": "959e9abb"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataframe.drop(columns = ['rating','ts']), dataframe.rating, test_size=0.2, random_state=42, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ebae8",
   "metadata": {
    "id": "da5ebae8"
   },
   "source": [
    "Напишем класс для хранения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388d1e5d",
   "metadata": {
    "id": "388d1e5d"
   },
   "outputs": [],
   "source": [
    "class RatingsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y=None):\n",
    "\n",
    "        self.users = X.user_id\n",
    "        self.items = X.item_id\n",
    "        self.ratings = y\n",
    "        \n",
    "    def __len__(self,):\n",
    "\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        return self.users[i], self.items[i], self.ratings[i]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate(batch):\n",
    "        \n",
    "        users = torch.tensor([elem[0] for elem in batch])\n",
    "        items = torch.tensor([elem[1] for elem in batch])\n",
    "        ratings = torch.tensor([elem[2] for elem in batch])    \n",
    "        \n",
    "        return users, items, ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3861e6b7",
   "metadata": {
    "id": "3861e6b7"
   },
   "source": [
    "Обработка данных для surprise SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961caec8",
   "metadata": {
    "id": "961caec8"
   },
   "outputs": [],
   "source": [
    "reader = surprise.Reader(rating_scale=(0, 10)) # Зададим разброс оценок\n",
    "data = surprise.Dataset.load_from_df(dataframe[['user_id', 'item_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d62ca5",
   "metadata": {
    "id": "c0d62ca5"
   },
   "outputs": [],
   "source": [
    "train_data_surprise, test_data_surprise = surprise.model_selection.train_test_split(data, test_size=0.2, random_state=42, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb31ee4",
   "metadata": {
    "id": "6fb31ee4"
   },
   "source": [
    "# Реализация моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83301f1f",
   "metadata": {
    "id": "83301f1f"
   },
   "source": [
    "## 1. SVD(Funk MF + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30cd21",
   "metadata": {
    "id": "0c30cd21"
   },
   "source": [
    "Метод SVD был честно реализован мной в дз1. Сейчас воспользуемся готовой реализацией из библиотеки surprise, так как хочется протестировать модели на одном большом датасете REKKO, а моя реализация не позволяет этого сделать, так как затрачивает слишком много памяти. Скорее всего, в реализации surprise используются sparse matrixes, так как в матрице рейтингов R действительно известно мало значений. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a06e41",
   "metadata": {
    "id": "35a06e41"
   },
   "source": [
    "С помощью CV оценим оценим качество модели SVD для 8, 10 и 12 факторов в разложении матрицы рейтингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393fbed",
   "metadata": {
    "id": "7393fbed",
    "outputId": "f79518d6-c987-49e2-9ddf-e75b57c67ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8-factors SVD: 1.8485271015417968\n",
      "10-factors SVD: 1.8501988296353138\n",
      "12-factors SVD: 1.8518200539191731\n"
     ]
    }
   ],
   "source": [
    "for k in [8, 10, 12]:\n",
    "    algo = SVD(n_factors = k,random_state = 42, verbose = False) #отключим вывод логирования\n",
    "    cv = surprise.model_selection.cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    print(str(k)+'-factors SVD:',np.mean(cv['test_rmse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tsUMQWHQH9hE",
   "metadata": {
    "id": "tsUMQWHQH9hE"
   },
   "source": [
    "Видим, что наилучшее качество получилось у модели с 8 факторами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a642e",
   "metadata": {
    "id": "db7a642e"
   },
   "source": [
    "## 2. NeuMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded75264",
   "metadata": {
    "id": "ded75264"
   },
   "source": [
    "https://towardsdatascience.com/neural-collaborative-filtering-96cef1009401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adc527f6",
   "metadata": {
    "id": "adc527f6"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, input_size, output_size, activation = True, dropout = 0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        if activation:\n",
    "            self.activation = nn.ReLU()\n",
    "        else:\n",
    "            nn.Identity()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.linear(x)\n",
    "        y2 = self.activation(y1)\n",
    "        y3 = self.dropout(y2)\n",
    "        return y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acb77aab",
   "metadata": {
    "id": "acb77aab"
   },
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors, activation, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_factors = n_factors\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.p = dropout\n",
    "   \n",
    "        self.u_emb = nn.Embedding(self.n_users, self.n_factors)\n",
    "        self.i_emb = nn.Embedding(self.n_items, self.n_factors)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(self.p)\n",
    "        self.out_linear = torch.nn.Linear(in_features = self.n_factors, out_features = 1)\n",
    "\n",
    "    def forward(self, users, items): \n",
    "        \n",
    "        features = torch.mul(self.u_emb(users), self.i_emb(items))\n",
    "        \n",
    "        out = self.dropout(features)\n",
    "        \n",
    "        return self.out_linear(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ce53a27",
   "metadata": {
    "id": "4ce53a27"
   },
   "outputs": [],
   "source": [
    "n_users = len(np.unique(dataframe.user_id))\n",
    "n_items = len(np.unique(dataframe.item_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a428db04",
   "metadata": {
    "id": "a428db04"
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd949ad6",
   "metadata": {
    "id": "dd949ad6"
   },
   "outputs": [],
   "source": [
    "def RMSELoss(y_true, y_pred):\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d39215e",
   "metadata": {
    "id": "7d39215e"
   },
   "outputs": [],
   "source": [
    "def run_epoch(stage, model, dataloader, loss_fn, optimizer, epoch, device):\n",
    "    \n",
    "    if stage == \"train\":\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.eval()\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc=f\"epoch: {str(epoch).zfill(3)} | {stage:5}\"):\n",
    "        us, its, ys_true = batch\n",
    "                \n",
    "        ys_pred = model(us.to(device), its.to(device))\n",
    "        loss = loss_fn(ys_pred, ys_true.to(device))\n",
    "\n",
    "        if stage == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        losses.append(loss.detach().cpu().item())\n",
    "    if stage == \"train\":\n",
    "        scheduler.step(np.mean(losses))\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f1ef2",
   "metadata": {
    "id": "976f1ef2"
   },
   "source": [
    "Будем контролировать значение целевой метрики на тестовой выборке и сохранять чекпоинт модели в случае, если он лучший"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88807bf3",
   "metadata": {
    "id": "88807bf3"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, filename):\n",
    "\n",
    "    with open(filename, \"wb\") as fp:\n",
    "        torch.save(model.state_dict(), fp)\n",
    "\n",
    "def load_checkpoint(model, filename):\n",
    "\n",
    "    with open(filename, \"rb\") as fp:\n",
    "        state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "    \n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df3ec61f",
   "metadata": {
    "id": "df3ec61f"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, output_dir):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    best_val_loss_epoch = -1\n",
    "    best_val_loss_fn = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = run_epoch(\"train\", model, dataloader_train, loss_fn, optimizer, epoch, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss = run_epoch(\"val\", model, dataloader_val, loss_fn, optimizer, epoch, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"epoch: {str(epoch).zfill(3)} | train_loss: {train_loss:5.3f}, val_loss: {val_loss:5.3f} (best: {best_val_loss:5.3f})\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "\n",
    "            best_val_loss = val_loss\n",
    "            best_val_loss_epoch = epoch\n",
    "\n",
    "            output_fn = os.path.join(output_dir, f\"epoch={str(epoch).zfill(2)}_valloss={best_val_loss:.3f}.pth.tar\")\n",
    "            save_checkpoint(model, output_fn)\n",
    "            print(f\"New checkpoint saved to {output_fn}\")\n",
    "\n",
    "            best_val_loss_fn = output_fn\n",
    "\n",
    "        print()\n",
    "\n",
    "    print (f\"Best val_loss = {best_val_loss:.3f} reached at epoch {best_val_loss_epoch}\")\n",
    "    load_checkpoint(model, best_val_loss_fn)\n",
    "\n",
    "    return train_losses, val_losses, best_val_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95912af1",
   "metadata": {
    "id": "95912af1"
   },
   "outputs": [],
   "source": [
    "TrainDataset = RatingsDataset(X_train, y_train)\n",
    "ValDataset = RatingsDataset(X_test.reset_index(drop = True), y_test.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81893bd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81893bd3",
    "outputId": "72354398-0638-4560-dfab-22cd33a73300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "lr = 3e-4\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a812b68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a812b68",
    "outputId": "4762a0a5-a277-413d-ee27-1734161d689f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(TrainDataset, \n",
    "                              collate_fn=RatingsDataset.collate, \n",
    "                              batch_size=batch_size, shuffle=True, drop_last=True, \n",
    "                              num_workers=4, pin_memory=True)\n",
    "\n",
    "dataloader_val = DataLoader(ValDataset, \n",
    "                            collate_fn=RatingsDataset.collate, \n",
    "                            batch_size=batch_size, shuffle=False, drop_last=False, \n",
    "                            num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QsSopnPlwrZS",
   "metadata": {
    "id": "QsSopnPlwrZS"
   },
   "source": [
    "Проверим, что модель обучается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "FYkzVWz8wpfY",
   "metadata": {
    "id": "FYkzVWz8wpfY"
   },
   "outputs": [],
   "source": [
    "model = MF(n_users, n_items, n_factors = 10, activation = True, dropout = 0.5)\n",
    "loss_fn = RMSELoss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "MvAZnUM9wph0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvAZnUM9wph0",
    "outputId": "b2fb0747-8af7-4b5f-b69d-302dc096e5ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2742/2742 [00:13<00:00, 200.92it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 686/686 [00:02<00:00, 240.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 7.799, val_loss: 7.439 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=7.439.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2742/2742 [00:13<00:00, 207.25it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 686/686 [00:04<00:00, 160.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.002, val_loss: 6.654 (best: 7.439)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=6.654.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2742/2742 [00:16<00:00, 167.05it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 686/686 [00:02<00:00, 287.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 6.223, val_loss: 5.882 (best: 6.654)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=5.882.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2742/2742 [00:12<00:00, 215.69it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 686/686 [00:02<00:00, 301.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 5.459, val_loss: 5.127 (best: 5.882)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=5.127.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2742/2742 [00:12<00:00, 219.43it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 686/686 [00:02<00:00, 294.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 4.715, val_loss: 4.396 (best: 5.127)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=4.396.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2742/2742 [00:12<00:00, 212.75it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 686/686 [00:02<00:00, 288.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 4.004, val_loss: 3.706 (best: 4.396)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=3.706.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2742/2742 [00:12<00:00, 213.68it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 686/686 [00:02<00:00, 297.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.346, val_loss: 3.082 (best: 3.706)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=3.082.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2742/2742 [00:12<00:00, 215.42it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 686/686 [00:02<00:00, 306.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.778, val_loss: 2.569 (best: 3.082)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.569.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2742/2742 [00:12<00:00, 211.55it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 686/686 [00:02<00:00, 304.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.356, val_loss: 2.230 (best: 2.569)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.230.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2742/2742 [00:12<00:00, 216.65it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 686/686 [00:02<00:00, 301.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.129, val_loss: 2.091 (best: 2.230)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.091.pth.tar\n",
      "\n",
      "Best val_loss = 2.091 reached at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, best_val_loss, model = run_experiment(\n",
    "    model, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "O9Si1FY2wpkq",
   "metadata": {
    "id": "O9Si1FY2wpkq"
   },
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses, title):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.title(title)\n",
    "    plt.plot(train_losses, label=\"train\")\n",
    "    plt.plot(val_losses, label=\"val\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "p9CM_pOexAoO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "p9CM_pOexAoO",
    "outputId": "6c45d39d-a74b-4b5d-fac9-28a967cedfbe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(train_losses, val_losses, title=\"MF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d1b94",
   "metadata": {
    "id": "b98d1b94"
   },
   "source": [
    "### Валидация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ELewouQpyz7e",
   "metadata": {
    "id": "ELewouQpyz7e"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "lr = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1OorXXuBvLob",
   "metadata": {
    "id": "1OorXXuBvLob"
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfiOqee9v_6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfiOqee9v_6H",
    "outputId": "2ddd5a77-293b-4508-b72e-9b7d268893a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.57it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 8.156, val_loss: 7.874 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=7.874.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.60it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.497, val_loss: 7.218 (best: 7.874)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=7.218.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.53it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 318.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 6.843, val_loss: 6.569 (best: 7.218)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=6.569.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:11<00:00, 196.68it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 6.197, val_loss: 5.927 (best: 6.569)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=5.927.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:12<00:00, 183.05it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 5.560, val_loss: 5.297 (best: 5.927)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=5.297.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.45it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 4.937, val_loss: 4.684 (best: 5.297)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=4.684.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.51it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 4.333, val_loss: 4.094 (best: 4.684)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=4.094.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.68it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 3.759, val_loss: 3.540 (best: 4.094)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=3.540.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.65it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 3.229, val_loss: 3.040 (best: 3.540)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=3.040.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.57it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.767, val_loss: 2.624 (best: 3.040)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.624.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:11<00:00, 197.71it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 304.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.409, val_loss: 2.326 (best: 2.624)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.326.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:10<00:00, 218.90it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 317.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.185, val_loss: 2.168 (best: 2.326)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.168.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:10<00:00, 216.80it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 248.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.095, val_loss: 2.124 (best: 2.168)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.124.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.55it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 257.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.080, val_loss: 2.120 (best: 2.124)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.120.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 2285/2285 [00:11<00:00, 194.92it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 233.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.080, val_loss: 2.120 (best: 2.120)\n",
      "New checkpoint saved to checkpoints/epoch=14_valloss=2.120.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 2285/2285 [00:13<00:00, 172.02it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 304.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.080, val_loss: 2.120 (best: 2.120)\n",
      "New checkpoint saved to checkpoints/epoch=15_valloss=2.120.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 2285/2285 [00:10<00:00, 218.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.080, val_loss: 2.120 (best: 2.120)\n",
      "New checkpoint saved to checkpoints/epoch=16_valloss=2.120.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.13it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 307.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.080, val_loss: 2.120 (best: 2.120)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.07it/s]\n",
      "epoch: 018 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 299.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.080, val_loss: 2.120 (best: 2.120)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 2285/2285 [00:10<00:00, 217.01it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 302.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.080, val_loss: 2.120 (best: 2.120)\n",
      "\n",
      "Best val_loss = 2.120 reached at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:10<00:00, 218.54it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 304.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 8.256, val_loss: 7.891 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=7.891.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.50it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 308.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.595, val_loss: 7.236 (best: 7.891)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=7.236.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.02it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 306.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 6.940, val_loss: 6.587 (best: 7.236)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=6.587.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:12<00:00, 177.74it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 6.291, val_loss: 5.948 (best: 6.587)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=5.948.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.76it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 316.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 5.652, val_loss: 5.320 (best: 5.948)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=5.320.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.73it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 5.025, val_loss: 4.708 (best: 5.320)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=4.708.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.69it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 4.416, val_loss: 4.121 (best: 4.708)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=4.121.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.68it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 3.835, val_loss: 3.570 (best: 4.121)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=3.570.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.49it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 3.294, val_loss: 3.074 (best: 3.570)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=3.074.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.91it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.817, val_loss: 2.660 (best: 3.074)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.660.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.10it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.437, val_loss: 2.366 (best: 2.660)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.366.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.56it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 317.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.189, val_loss: 2.212 (best: 2.366)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.212.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.36it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.079, val_loss: 2.173 (best: 2.212)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.173.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.20it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.058, val_loss: 2.173 (best: 2.173)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.173.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.29it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.056, val_loss: 2.173 (best: 2.173)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.38it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 308.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.056, val_loss: 2.173 (best: 2.173)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.51it/s]\n",
      "epoch: 016 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.056, val_loss: 2.173 (best: 2.173)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00018: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 317.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.056, val_loss: 2.173 (best: 2.173)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.99it/s]\n",
      "epoch: 018 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 305.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.056, val_loss: 2.173 (best: 2.173)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 316.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.056, val_loss: 2.173 (best: 2.173)\n",
      "\n",
      "Best val_loss = 2.173 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.53it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 317.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 8.099, val_loss: 7.812 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=7.812.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.14it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.439, val_loss: 7.158 (best: 7.812)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=7.158.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.14it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 6.786, val_loss: 6.510 (best: 7.158)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=6.510.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:11<00:00, 192.73it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 246.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 6.139, val_loss: 5.871 (best: 6.510)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=5.871.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.38it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 317.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 5.503, val_loss: 5.245 (best: 5.871)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=5.245.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.99it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 4.881, val_loss: 4.636 (best: 5.245)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=4.636.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.60it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 4.278, val_loss: 4.052 (best: 4.636)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=4.052.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:12<00:00, 186.58it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 288.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 3.706, val_loss: 3.506 (best: 4.052)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=3.506.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.72it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 3.179, val_loss: 3.017 (best: 3.506)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=3.017.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.34it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.723, val_loss: 2.616 (best: 3.017)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.616.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.65it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.374, val_loss: 2.337 (best: 2.616)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.337.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.44it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 307.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.161, val_loss: 2.198 (best: 2.337)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.198.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.29it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.079, val_loss: 2.163 (best: 2.198)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.163.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.47it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.068, val_loss: 2.161 (best: 2.163)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.161.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.80it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.067, val_loss: 2.161 (best: 2.161)\n",
      "New checkpoint saved to checkpoints/epoch=14_valloss=2.161.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.00it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.067, val_loss: 2.161 (best: 2.161)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.067, val_loss: 2.161 (best: 2.161)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.12it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.067, val_loss: 2.161 (best: 2.161)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 308.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.067, val_loss: 2.161 (best: 2.161)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.23it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.067, val_loss: 2.161 (best: 2.161)\n",
      "\n",
      "Best val_loss = 2.161 reached at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.98it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 7.809, val_loss: 7.522 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=7.522.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.51it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.152, val_loss: 6.867 (best: 7.522)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=6.867.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.47it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 6.502, val_loss: 6.221 (best: 6.867)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=6.221.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.48it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 308.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 5.861, val_loss: 5.584 (best: 6.221)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=5.584.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:13<00:00, 175.71it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 5.230, val_loss: 4.960 (best: 5.584)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=4.960.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.16it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 4.616, val_loss: 4.355 (best: 4.960)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=4.355.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.07it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 4.027, val_loss: 3.779 (best: 4.355)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=3.779.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.95it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 316.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 3.473, val_loss: 3.247 (best: 3.779)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=3.247.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.77it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 316.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.976, val_loss: 2.783 (best: 3.247)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.783.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.99it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.564, val_loss: 2.420 (best: 2.783)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.420.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.49it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.273, val_loss: 2.192 (best: 2.420)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.192.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.74it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 316.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.124, val_loss: 2.099 (best: 2.192)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.099.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.45it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.083, val_loss: 2.084 (best: 2.099)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.084.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.40it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.080, val_loss: 2.083 (best: 2.084)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.083.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.44it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.080, val_loss: 2.083 (best: 2.083)\n",
      "New checkpoint saved to checkpoints/epoch=14_valloss=2.083.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.080, val_loss: 2.083 (best: 2.083)\n",
      "New checkpoint saved to checkpoints/epoch=15_valloss=2.083.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.49it/s]\n",
      "epoch: 016 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.080, val_loss: 2.083 (best: 2.083)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.78it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 305.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.080, val_loss: 2.083 (best: 2.083)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 318.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.080, val_loss: 2.083 (best: 2.083)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.69it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 308.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.080, val_loss: 2.083 (best: 2.083)\n",
      "\n",
      "Best val_loss = 2.083 reached at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.12it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 8.425, val_loss: 8.066 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=8.066.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:10<00:00, 226.70it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.764, val_loss: 7.410 (best: 8.066)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=7.410.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.29it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 7.107, val_loss: 6.761 (best: 7.410)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=6.761.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.08it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 317.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 6.456, val_loss: 6.119 (best: 6.761)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=6.119.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.43it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 5.814, val_loss: 5.488 (best: 6.119)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=5.488.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:12<00:00, 176.27it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 5.184, val_loss: 4.873 (best: 5.488)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=4.873.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.74it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 4.570, val_loss: 4.280 (best: 4.873)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=4.280.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:10<00:00, 227.00it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 3.980, val_loss: 3.719 (best: 4.280)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=3.719.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.68it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 3.427, val_loss: 3.208 (best: 3.719)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=3.208.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.58it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.931, val_loss: 2.772 (best: 3.208)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.772.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:10<00:00, 226.03it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.523, val_loss: 2.445 (best: 2.772)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.445.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.55it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.238, val_loss: 2.256 (best: 2.445)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.256.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.57it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.096, val_loss: 2.194 (best: 2.256)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.194.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.44it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.059, val_loss: 2.190 (best: 2.194)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.190.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.51it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.057, val_loss: 2.190 (best: 2.190)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.15it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.057, val_loss: 2.190 (best: 2.190)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 318.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.057, val_loss: 2.190 (best: 2.190)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.47it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.056, val_loss: 2.190 (best: 2.190)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.37it/s]\n",
      "epoch: 018 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 317.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.056, val_loss: 2.191 (best: 2.190)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.16it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.056, val_loss: 2.191 (best: 2.190)\n",
      "\n",
      "Best val_loss = 2.190 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.38it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 7.870, val_loss: 7.577 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=7.577.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.34it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 304.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.213, val_loss: 6.924 (best: 7.577)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=6.924.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.58it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 6.561, val_loss: 6.278 (best: 6.924)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=6.278.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.73it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 5.918, val_loss: 5.642 (best: 6.278)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=5.642.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.41it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 5.286, val_loss: 5.019 (best: 5.642)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=5.019.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.51it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:05<00:00, 200.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 4.670, val_loss: 4.416 (best: 5.019)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=4.416.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:11<00:00, 202.37it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 4.076, val_loss: 3.841 (best: 4.416)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=3.841.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.82it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 3.517, val_loss: 3.309 (best: 3.841)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=3.309.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.18it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 318.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 3.012, val_loss: 2.844 (best: 3.309)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.844.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.09it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 317.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.588, val_loss: 2.478 (best: 2.844)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.478.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.94it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.284, val_loss: 2.245 (best: 2.478)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.245.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.48it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.120, val_loss: 2.147 (best: 2.245)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.147.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.80it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.071, val_loss: 2.130 (best: 2.147)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.130.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.52it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.067, val_loss: 2.130 (best: 2.130)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.130.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.49it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.067, val_loss: 2.130 (best: 2.130)\n",
      "New checkpoint saved to checkpoints/epoch=14_valloss=2.130.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.49it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 316.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.067, val_loss: 2.129 (best: 2.130)\n",
      "New checkpoint saved to checkpoints/epoch=15_valloss=2.129.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.067, val_loss: 2.129 (best: 2.129)\n",
      "New checkpoint saved to checkpoints/epoch=16_valloss=2.129.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 2285/2285 [00:10<00:00, 225.12it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.067, val_loss: 2.129 (best: 2.129)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.067, val_loss: 2.130 (best: 2.129)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.07it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.067, val_loss: 2.129 (best: 2.129)\n",
      "\n",
      "Best val_loss = 2.129 reached at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.73it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 317.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 7.944, val_loss: 7.672 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=7.672.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.44it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 318.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.286, val_loss: 7.019 (best: 7.672)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=7.019.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.68it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 6.635, val_loss: 6.372 (best: 7.019)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=6.372.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.18it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 305.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 5.991, val_loss: 5.735 (best: 6.372)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=5.735.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:10<00:00, 218.89it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 5.358, val_loss: 5.110 (best: 5.735)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=5.110.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.82it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 300.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 4.741, val_loss: 4.504 (best: 5.110)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=4.504.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:10<00:00, 211.49it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:06<00:00, 189.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 4.145, val_loss: 3.926 (best: 4.504)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=3.926.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.37it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 3.583, val_loss: 3.388 (best: 3.926)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=3.388.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.92it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 3.072, val_loss: 2.914 (best: 3.388)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.914.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.93it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.639, val_loss: 2.533 (best: 2.914)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.533.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.48it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.321, val_loss: 2.280 (best: 2.533)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.280.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.16it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.143, val_loss: 2.166 (best: 2.280)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.166.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.01it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.086, val_loss: 2.142 (best: 2.166)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.142.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.28it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.080, val_loss: 2.141 (best: 2.142)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.141.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.86it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 301.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.080, val_loss: 2.141 (best: 2.141)\n",
      "New checkpoint saved to checkpoints/epoch=14_valloss=2.141.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.01it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.080, val_loss: 2.141 (best: 2.141)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 308.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.080, val_loss: 2.141 (best: 2.141)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.67it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.080, val_loss: 2.141 (best: 2.141)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.080, val_loss: 2.141 (best: 2.141)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.81it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.080, val_loss: 2.141 (best: 2.141)\n",
      "\n",
      "Best val_loss = 2.141 reached at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.30it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 307.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 8.095, val_loss: 7.726 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=7.726.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.41it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 315.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.436, val_loss: 7.072 (best: 7.726)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=7.072.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.71it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 6.782, val_loss: 6.425 (best: 7.072)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=6.425.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.98it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 6.135, val_loss: 5.787 (best: 6.425)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=5.787.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.97it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 5.499, val_loss: 5.161 (best: 5.787)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=5.161.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:10<00:00, 217.50it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 300.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 4.876, val_loss: 4.553 (best: 5.161)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=4.553.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:10<00:00, 218.86it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 4.272, val_loss: 3.971 (best: 4.553)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=3.971.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:12<00:00, 176.53it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 3.699, val_loss: 3.429 (best: 3.971)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=3.429.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.70it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 3.171, val_loss: 2.946 (best: 3.429)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.946.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.69it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 308.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.715, val_loss: 2.555 (best: 2.946)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.555.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.58it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.364, val_loss: 2.291 (best: 2.555)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.291.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.40it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.150, val_loss: 2.167 (best: 2.291)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.167.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.86it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.069, val_loss: 2.144 (best: 2.167)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.144.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.43it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 306.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.057, val_loss: 2.145 (best: 2.144)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.07it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.056, val_loss: 2.145 (best: 2.144)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.11it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.057, val_loss: 2.145 (best: 2.144)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.056, val_loss: 2.145 (best: 2.144)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.25it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.056, val_loss: 2.145 (best: 2.144)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.056, val_loss: 2.145 (best: 2.144)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.30it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.057, val_loss: 2.145 (best: 2.144)\n",
      "\n",
      "Best val_loss = 2.144 reached at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:10<00:00, 223.12it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 316.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 8.373, val_loss: 8.075 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=8.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:10<00:00, 224.07it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 7.712, val_loss: 7.418 (best: 8.075)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=7.418.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.06it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 307.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 7.056, val_loss: 6.766 (best: 7.418)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=6.766.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.56it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 6.406, val_loss: 6.122 (best: 6.766)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=6.122.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.35it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 5.766, val_loss: 5.488 (best: 6.122)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=5.488.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.86it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 312.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 5.137, val_loss: 4.869 (best: 5.488)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=4.869.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.29it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 4.525, val_loss: 4.272 (best: 4.869)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=4.272.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:10<00:00, 218.56it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 300.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 3.938, val_loss: 3.705 (best: 4.272)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=3.705.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:13<00:00, 174.82it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 309.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 3.390, val_loss: 3.186 (best: 3.705)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=3.186.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:10<00:00, 219.40it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.902, val_loss: 2.741 (best: 3.186)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.741.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.88it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.503, val_loss: 2.403 (best: 2.741)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.403.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.15it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 314.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.231, val_loss: 2.204 (best: 2.403)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.204.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.28it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 311.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.100, val_loss: 2.133 (best: 2.204)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.133.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.31it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.069, val_loss: 2.124 (best: 2.133)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.124.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.90it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 308.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.068, val_loss: 2.124 (best: 2.124)\n",
      "New checkpoint saved to checkpoints/epoch=14_valloss=2.124.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.76it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 302.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.067, val_loss: 2.124 (best: 2.124)\n",
      "New checkpoint saved to checkpoints/epoch=15_valloss=2.124.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 2285/2285 [00:10<00:00, 222.72it/s]\n",
      "epoch: 016 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 313.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.067, val_loss: 2.124 (best: 2.124)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 2285/2285 [00:10<00:00, 220.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00018: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 307.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.067, val_loss: 2.124 (best: 2.124)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 2285/2285 [00:10<00:00, 221.38it/s]\n",
      "epoch: 018 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 310.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.067, val_loss: 2.124 (best: 2.124)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 2285/2285 [00:10<00:00, 218.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 316.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.067, val_loss: 2.124 (best: 2.124)\n",
      "\n",
      "Best val_loss = 2.124 reached at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_KFold_losses = []\n",
    "for k in [8, 10, 12]:\n",
    "    val_losses_KFold = []\n",
    "    train_losses_KFold = []\n",
    "    models_KFold = list(np.zeros(cv.get_n_splits()))\n",
    "    i = 0\n",
    "\n",
    "    for train_index, test_index in cv.split(dataframe.drop(columns = ['rating','ts'])):\n",
    "        x_train, x_test = dataframe.drop(columns = ['rating','ts']).iloc[train_index], dataframe.drop(columns = ['rating','ts']).iloc[test_index]\n",
    "        y_train, y_test = dataframe['rating'].iloc[train_index], dataframe['rating'].iloc[test_index]\n",
    "        \n",
    "        TrainDataset = RatingsDataset(x_train.reset_index(drop = True), y_train.reset_index(drop = True))\n",
    "        ValDataset = RatingsDataset(x_test.reset_index(drop = True), y_test.reset_index(drop = True))\n",
    "        \n",
    "        dataloader_train = DataLoader(TrainDataset, \n",
    "                                  collate_fn=RatingsDataset.collate, \n",
    "                                  batch_size=batch_size, shuffle=True, drop_last=True, \n",
    "                                  num_workers=4, pin_memory=True)\n",
    "\n",
    "        dataloader_val = DataLoader(ValDataset, \n",
    "                                collate_fn=RatingsDataset.collate, \n",
    "                                batch_size=batch_size, shuffle=False, drop_last=False, \n",
    "                                num_workers=4, pin_memory=True)\n",
    "        \n",
    "        models_KFold[i] = MF(n_users, n_items, n_factors = k, activation = True, dropout = True)\n",
    "\n",
    "        optimizer = torch.optim.Adam(models_KFold[i].parameters(), lr = lr)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)\n",
    "        \n",
    "        train_losses, val_losses, best_val_loss, models_KFold[i] = run_experiment(\n",
    "        models_KFold[i], dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints/\")\n",
    "        \n",
    "        train_losses_KFold.append(train_losses[-1])\n",
    "        val_losses_KFold.append(best_val_loss)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    mean_KFold_losses.append(np.mean(val_losses_KFold))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o15tC2_nAgZp",
   "metadata": {
    "id": "o15tC2_nAgZp"
   },
   "source": [
    "Посмотрим на средние значения RMSE по фолдам для 8, 10 и 12 факторов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e42214e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e42214e",
    "outputId": "f2c89bf8-fa29-491b-cc20-513b6a8e89d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.1510666903965534, 2.1340792924817573, 2.136099092568904]\n"
     ]
    }
   ],
   "source": [
    "print(mean_KFold_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ouaxY4z4Hydj",
   "metadata": {
    "id": "ouaxY4z4Hydj"
   },
   "source": [
    "Видим, что наилучшее качество получилось для модели с 10 факторами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wZgYF9glMKZE",
   "metadata": {
    "id": "wZgYF9glMKZE"
   },
   "source": [
    "Добавим в нейросеть линейные слои, которые будут преобразовывать другие эмбеддинги, а в конце соединим их с матричной факторизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4lYECUfeLnc_",
   "metadata": {
    "id": "4lYECUfeLnc_"
   },
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors_mf, n_factors_mlp, hidden_layers_sizes, activation, dropouts_mlp, dropout_mf):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_factors_mf = n_factors_mf\n",
    "        self.n_factors_mlp = n_factors_mlp\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.p = dropout_mf\n",
    "        self.dropouts_mlp = dropouts_mlp\n",
    "    \n",
    "        # mf part\n",
    "        self.u_emb_mf = nn.Embedding(self.n_users, self.n_factors_mf)\n",
    "        self.i_emb_mf = nn.Embedding(self.n_items, self.n_factors_mf)\n",
    "\n",
    "        self.dropout_mf = torch.nn.Dropout(self.p)\n",
    "        \n",
    "        # mlp part\n",
    "        self.u_emb_mlp = nn.Embedding(self.n_users, self.n_factors_mlp)\n",
    "        self.i_emb_mlp = nn.Embedding(self.n_items, self.n_factors_mlp)\n",
    "        \n",
    "        \n",
    "        layers = [Block(2*n_factors_mlp, hidden_layers_sizes[0], activation = activation, dropout = dropouts_mlp[0])]\n",
    "        \n",
    "        for i in range(len(hidden_layers_sizes)-1):\n",
    "            layers.append(Block(hidden_layers_sizes[i], hidden_layers_sizes[i+1], activation = activation, dropout = dropouts_mlp[i+1]))\n",
    "              \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        self.out_linear = torch.nn.Linear(in_features = hidden_layers_sizes[-1] + self.n_factors_mf, out_features = 1)\n",
    "\n",
    "    def forward(self, users, items): \n",
    "        \n",
    "        features_mf = torch.mul(self.u_emb_mf(users), self.i_emb_mf(items))\n",
    "        features_mlp = torch.cat([self.u_emb_mlp(users), self.i_emb_mlp(items)], dim=-1)\n",
    "        \n",
    "        out_mlp = self.mlp(features_mlp)\n",
    "        out_mf = self.dropout_mf(features_mf)\n",
    "\n",
    "        out = torch.cat([out_mlp, out_mf], dim=-1)\n",
    "        return self.out_linear(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JhBKVxC6gQuq",
   "metadata": {
    "id": "JhBKVxC6gQuq"
   },
   "source": [
    "Проверим, что модель обучается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ZuJfV3m2ghQZ",
   "metadata": {
    "id": "ZuJfV3m2ghQZ"
   },
   "outputs": [],
   "source": [
    "TrainDataset = RatingsDataset(X_train, y_train)\n",
    "ValDataset = RatingsDataset(X_test.reset_index(drop = True), y_test.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "kZCPK4cmghQZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZCPK4cmghQZ",
    "outputId": "2599544f-3684-43c2-adb2-f181e54ce72c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "lr = 3e-4\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4BaNJhkLghQa",
   "metadata": {
    "id": "4BaNJhkLghQa"
   },
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(TrainDataset, \n",
    "                              collate_fn=RatingsDataset.collate, \n",
    "                              batch_size=batch_size, shuffle=True, drop_last=True, \n",
    "                              num_workers=4, pin_memory=True)\n",
    "\n",
    "dataloader_val = DataLoader(ValDataset, \n",
    "                            collate_fn=RatingsDataset.collate, \n",
    "                            batch_size=batch_size, shuffle=False, drop_last=False, \n",
    "                            num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9rjusPtEgqao",
   "metadata": {
    "id": "9rjusPtEgqao"
   },
   "outputs": [],
   "source": [
    "model = NeuMF(n_users, n_items, n_factors_mf = 10, n_factors_mlp = 10, hidden_layers_sizes = [16, 16], \n",
    "              activation = True, dropouts_mlp = [0.9,0.9], dropout_mf = 0.5)\n",
    "loss_fn = RMSELoss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "TzPVOU0lgqap",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzPVOU0lgqap",
    "outputId": "a7afdbef-e8ce-436e-8d2d-bd1dd2ed2d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2742/2742 [00:17<00:00, 160.02it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 686/686 [00:02<00:00, 271.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.518, val_loss: 3.943 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=3.943.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2742/2742 [00:17<00:00, 158.07it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 686/686 [00:02<00:00, 274.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 4.702, val_loss: 3.146 (best: 3.943)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.146.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2742/2742 [00:16<00:00, 161.40it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 686/686 [00:02<00:00, 278.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.224, val_loss: 2.942 (best: 3.146)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=2.942.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2742/2742 [00:16<00:00, 161.52it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 686/686 [00:02<00:00, 270.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 3.813, val_loss: 2.731 (best: 2.942)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.731.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2742/2742 [00:23<00:00, 116.00it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 686/686 [00:02<00:00, 274.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.416, val_loss: 2.587 (best: 2.731)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.587.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2742/2742 [00:17<00:00, 157.30it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 686/686 [00:02<00:00, 265.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.056, val_loss: 2.405 (best: 2.587)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.405.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2742/2742 [00:19<00:00, 139.41it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 686/686 [00:02<00:00, 275.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 2.731, val_loss: 2.281 (best: 2.405)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.281.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2742/2742 [00:20<00:00, 135.03it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 686/686 [00:02<00:00, 271.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.461, val_loss: 2.181 (best: 2.281)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.181.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2742/2742 [00:17<00:00, 153.16it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 686/686 [00:03<00:00, 218.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.259, val_loss: 2.123 (best: 2.181)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.123.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2742/2742 [00:20<00:00, 136.60it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 686/686 [00:02<00:00, 268.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.134, val_loss: 2.085 (best: 2.123)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.085.pth.tar\n",
      "\n",
      "Best val_loss = 2.085 reached at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, best_val_loss, model = run_experiment(\n",
    "    model, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C5bgRMBFkIRv",
   "metadata": {
    "id": "C5bgRMBFkIRv"
   },
   "source": [
    "### Валидация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "S5D7mOarj55f",
   "metadata": {
    "id": "S5D7mOarj55f"
   },
   "outputs": [],
   "source": [
    "num_epochs = 14\n",
    "batch_size = 128\n",
    "lr = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "RWNFYw2tj55g",
   "metadata": {
    "id": "RWNFYw2tj55g"
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1ZX83tej55g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1ZX83tej55g",
    "outputId": "757081b3-95fa-454d-b5dc-fbf9533c15cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.17it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 278.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.761, val_loss: 4.344 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=4.344.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:13<00:00, 163.87it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 282.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 5.016, val_loss: 3.286 (best: 4.344)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.286.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:14<00:00, 162.24it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 281.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.486, val_loss: 3.054 (best: 3.286)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=3.054.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.16it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 4.129, val_loss: 2.873 (best: 3.054)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.873.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.97it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 285.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.790, val_loss: 2.725 (best: 2.873)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.725.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.11it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.465, val_loss: 2.560 (best: 2.725)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.560.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.29it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.157, val_loss: 2.431 (best: 2.560)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.431.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:14<00:00, 161.68it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 276.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.873, val_loss: 2.312 (best: 2.431)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.312.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.19it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 289.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.626, val_loss: 2.226 (best: 2.312)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.226.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.30it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.418, val_loss: 2.152 (best: 2.226)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.152.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.82it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.259, val_loss: 2.093 (best: 2.152)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.093.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.81it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 278.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.155, val_loss: 2.061 (best: 2.093)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.061.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.15it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.102, val_loss: 2.046 (best: 2.061)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.046.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:13<00:00, 163.39it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 277.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.084, val_loss: 2.041 (best: 2.046)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.041.pth.tar\n",
      "\n",
      "Best val_loss = 2.041 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:15<00:00, 148.29it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:05<00:00, 215.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.913, val_loss: 4.368 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=4.368.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.64it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 5.090, val_loss: 3.341 (best: 4.368)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.341.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.64it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.559, val_loss: 3.109 (best: 3.341)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=3.109.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.31it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 281.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 4.194, val_loss: 2.902 (best: 3.109)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.902.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.03it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.840, val_loss: 2.751 (best: 2.902)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.751.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.06it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.502, val_loss: 2.597 (best: 2.751)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.597.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.96it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.184, val_loss: 2.448 (best: 2.597)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.448.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.48it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 290.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.891, val_loss: 2.339 (best: 2.448)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.339.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.80it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 285.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.632, val_loss: 2.243 (best: 2.339)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.243.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.22it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.411, val_loss: 2.169 (best: 2.243)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.169.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.13it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.245, val_loss: 2.121 (best: 2.169)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.121.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.86it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.135, val_loss: 2.094 (best: 2.121)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.094.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.61it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.079, val_loss: 2.088 (best: 2.094)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.088.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.94it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.060, val_loss: 2.087 (best: 2.088)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.087.pth.tar\n",
      "\n",
      "Best val_loss = 2.087 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.65it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 287.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.531, val_loss: 4.132 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=4.132.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.42it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 277.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 4.902, val_loss: 3.282 (best: 4.132)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.282.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.30it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.461, val_loss: 3.108 (best: 3.282)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=3.108.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.66it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 290.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 4.094, val_loss: 2.919 (best: 3.108)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.919.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.00it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 287.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.750, val_loss: 2.735 (best: 2.919)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.735.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.42it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.415, val_loss: 2.582 (best: 2.735)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.582.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.68it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 279.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.106, val_loss: 2.441 (best: 2.582)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.441.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.22it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 281.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.822, val_loss: 2.327 (best: 2.441)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.327.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.72it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.574, val_loss: 2.224 (best: 2.327)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.224.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:13<00:00, 170.99it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.369, val_loss: 2.160 (best: 2.224)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.160.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.07it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 290.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.219, val_loss: 2.104 (best: 2.160)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.104.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.26it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 289.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.125, val_loss: 2.079 (best: 2.104)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.079.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:14<00:00, 156.47it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 289.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.081, val_loss: 2.069 (best: 2.079)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.069.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:14<00:00, 156.98it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 277.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.069, val_loss: 2.067 (best: 2.069)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.067.pth.tar\n",
      "\n",
      "Best val_loss = 2.067 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.96it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 277.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.783, val_loss: 4.119 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=4.119.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.15it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 4.984, val_loss: 3.320 (best: 4.119)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.320.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.43it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 287.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.540, val_loss: 3.082 (best: 3.320)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=3.082.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.84it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 281.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 4.197, val_loss: 2.925 (best: 3.082)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.925.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.57it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 281.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.852, val_loss: 2.746 (best: 2.925)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.746.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.63it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.522, val_loss: 2.608 (best: 2.746)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.608.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.56it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 282.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.214, val_loss: 2.465 (best: 2.608)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.465.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.56it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 288.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.925, val_loss: 2.338 (best: 2.465)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.338.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.71it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 289.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.670, val_loss: 2.247 (best: 2.338)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.247.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.80it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.452, val_loss: 2.159 (best: 2.247)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.159.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.56it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 281.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.284, val_loss: 2.101 (best: 2.159)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.101.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.02it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 287.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.170, val_loss: 2.062 (best: 2.101)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.062.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.98it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 288.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.108, val_loss: 2.049 (best: 2.062)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.049.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:13<00:00, 171.90it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 288.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.086, val_loss: 2.043 (best: 2.049)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.043.pth.tar\n",
      "\n",
      "Best val_loss = 2.043 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:13<00:00, 171.11it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.790, val_loss: 4.124 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=4.124.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.34it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 4.988, val_loss: 3.234 (best: 4.124)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.234.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.25it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 289.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.526, val_loss: 3.080 (best: 3.234)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=3.080.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:14<00:00, 158.42it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 285.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 4.166, val_loss: 2.848 (best: 3.080)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.848.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:14<00:00, 152.96it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 278.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.826, val_loss: 2.696 (best: 2.848)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.696.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.09it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 276.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.497, val_loss: 2.561 (best: 2.696)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.561.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:14<00:00, 158.18it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.181, val_loss: 2.435 (best: 2.561)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.435.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.85it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.893, val_loss: 2.328 (best: 2.435)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.328.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.40it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 287.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.638, val_loss: 2.238 (best: 2.328)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.238.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.05it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.422, val_loss: 2.169 (best: 2.238)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.169.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.55it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 290.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.255, val_loss: 2.119 (best: 2.169)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.119.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:13<00:00, 171.18it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 287.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.143, val_loss: 2.095 (best: 2.119)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.095.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.59it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.083, val_loss: 2.088 (best: 2.095)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.088.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.16it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.061, val_loss: 2.087 (best: 2.088)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.087.pth.tar\n",
      "\n",
      "Best val_loss = 2.087 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.32it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 285.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.749, val_loss: 4.173 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=4.173.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.89it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 291.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 5.021, val_loss: 3.288 (best: 4.173)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.288.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:13<00:00, 170.13it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 293.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.571, val_loss: 3.106 (best: 3.288)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=3.106.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.75it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 285.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 4.223, val_loss: 2.953 (best: 3.106)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.953.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.62it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 289.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.867, val_loss: 2.779 (best: 2.953)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.779.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.82it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.537, val_loss: 2.642 (best: 2.779)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.642.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.73it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 290.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.228, val_loss: 2.481 (best: 2.642)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.481.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.58it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:05<00:00, 219.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.935, val_loss: 2.365 (best: 2.481)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.365.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:14<00:00, 156.05it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 290.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.678, val_loss: 2.268 (best: 2.365)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.268.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:13<00:00, 169.00it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 281.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.456, val_loss: 2.174 (best: 2.268)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.174.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.64it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.284, val_loss: 2.124 (best: 2.174)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.124.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.88it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 290.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.165, val_loss: 2.088 (best: 2.124)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.088.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:13<00:00, 170.49it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 288.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.099, val_loss: 2.073 (best: 2.088)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.073.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.25it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.074, val_loss: 2.069 (best: 2.073)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.069.pth.tar\n",
      "\n",
      "Best val_loss = 2.069 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.73it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 279.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.824, val_loss: 4.484 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=4.484.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.87it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 288.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 4.975, val_loss: 3.257 (best: 4.484)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.257.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.23it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.445, val_loss: 3.052 (best: 3.257)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=3.052.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.97it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 285.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 4.090, val_loss: 2.873 (best: 3.052)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.873.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.96it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 287.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.745, val_loss: 2.704 (best: 2.873)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.704.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.88it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 282.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.428, val_loss: 2.564 (best: 2.704)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.564.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.42it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 288.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.121, val_loss: 2.415 (best: 2.564)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.415.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.24it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 288.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.843, val_loss: 2.307 (best: 2.415)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.307.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.62it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.597, val_loss: 2.213 (best: 2.307)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.213.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.67it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 287.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.394, val_loss: 2.128 (best: 2.213)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.128.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:13<00:00, 168.12it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 289.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.243, val_loss: 2.088 (best: 2.128)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.088.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.21it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.146, val_loss: 2.058 (best: 2.088)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.058.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:14<00:00, 159.26it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:05<00:00, 213.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.098, val_loss: 2.045 (best: 2.058)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.045.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.99it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.083, val_loss: 2.041 (best: 2.045)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.041.pth.tar\n",
      "\n",
      "Best val_loss = 2.041 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.30it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 281.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.923, val_loss: 4.314 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=4.314.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.58it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 5.120, val_loss: 3.292 (best: 4.314)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.292.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.19it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.559, val_loss: 3.044 (best: 3.292)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=3.044.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:13<00:00, 163.92it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 276.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 4.200, val_loss: 2.873 (best: 3.044)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.873.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.53it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.852, val_loss: 2.723 (best: 2.873)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.723.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.56it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 277.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.524, val_loss: 2.587 (best: 2.723)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.587.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.31it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.210, val_loss: 2.455 (best: 2.587)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.455.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.95it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 288.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.917, val_loss: 2.343 (best: 2.455)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.343.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.17it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 282.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.661, val_loss: 2.247 (best: 2.343)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.247.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:13<00:00, 163.84it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 280.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.440, val_loss: 2.183 (best: 2.247)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.183.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.82it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 279.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.269, val_loss: 2.123 (best: 2.183)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.123.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.73it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.151, val_loss: 2.099 (best: 2.123)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.099.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:14<00:00, 162.56it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 275.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.087, val_loss: 2.089 (best: 2.099)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.089.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:14<00:00, 162.71it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 278.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.062, val_loss: 2.087 (best: 2.089)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.087.pth.tar\n",
      "\n",
      "Best val_loss = 2.087 reached at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 2285/2285 [00:14<00:00, 162.01it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 277.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 6.768, val_loss: 4.329 (best:   inf)\n",
      "New checkpoint saved to checkpoints/epoch=00_valloss=4.329.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 2285/2285 [00:14<00:00, 162.46it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 287.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 5.032, val_loss: 3.317 (best: 4.329)\n",
      "New checkpoint saved to checkpoints/epoch=01_valloss=3.317.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 2285/2285 [00:15<00:00, 150.34it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 261.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.523, val_loss: 3.115 (best: 3.317)\n",
      "New checkpoint saved to checkpoints/epoch=02_valloss=3.115.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.96it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 279.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 4.166, val_loss: 2.932 (best: 3.115)\n",
      "New checkpoint saved to checkpoints/epoch=03_valloss=2.932.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.60it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 3.813, val_loss: 2.772 (best: 2.932)\n",
      "New checkpoint saved to checkpoints/epoch=04_valloss=2.772.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 2285/2285 [00:13<00:00, 163.95it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 279.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 3.478, val_loss: 2.615 (best: 2.772)\n",
      "New checkpoint saved to checkpoints/epoch=05_valloss=2.615.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.57it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 3.164, val_loss: 2.475 (best: 2.615)\n",
      "New checkpoint saved to checkpoints/epoch=06_valloss=2.475.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.54it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.873, val_loss: 2.345 (best: 2.475)\n",
      "New checkpoint saved to checkpoints/epoch=07_valloss=2.345.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.76it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 278.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.617, val_loss: 2.233 (best: 2.345)\n",
      "New checkpoint saved to checkpoints/epoch=08_valloss=2.233.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 2285/2285 [00:13<00:00, 167.03it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.404, val_loss: 2.172 (best: 2.233)\n",
      "New checkpoint saved to checkpoints/epoch=09_valloss=2.172.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 2285/2285 [00:13<00:00, 165.85it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 289.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.244, val_loss: 2.116 (best: 2.172)\n",
      "New checkpoint saved to checkpoints/epoch=10_valloss=2.116.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 2285/2285 [00:13<00:00, 166.25it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 284.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.138, val_loss: 2.083 (best: 2.116)\n",
      "New checkpoint saved to checkpoints/epoch=11_valloss=2.083.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 2285/2285 [00:13<00:00, 164.33it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 1143/1143 [00:04<00:00, 283.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.087, val_loss: 2.071 (best: 2.083)\n",
      "New checkpoint saved to checkpoints/epoch=12_valloss=2.071.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 2285/2285 [00:13<00:00, 163.67it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 1143/1143 [00:03<00:00, 286.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.070, val_loss: 2.068 (best: 2.071)\n",
      "New checkpoint saved to checkpoints/epoch=13_valloss=2.068.pth.tar\n",
      "\n",
      "Best val_loss = 2.068 reached at epoch 13\n"
     ]
    }
   ],
   "source": [
    "mean_KFold_losses = []\n",
    "for k in [8, 10, 12]:\n",
    "    val_losses_KFold = []\n",
    "    train_losses_KFold = []\n",
    "    models_KFold = list(np.zeros(cv.get_n_splits()))\n",
    "    i = 0\n",
    "\n",
    "    for train_index, test_index in cv.split(dataframe.drop(columns = ['rating','ts'])):\n",
    "        x_train, x_test = dataframe.drop(columns = ['rating','ts']).iloc[train_index], dataframe.drop(columns = ['rating','ts']).iloc[test_index]\n",
    "        y_train, y_test = dataframe['rating'].iloc[train_index], dataframe['rating'].iloc[test_index]\n",
    "        \n",
    "        TrainDataset = RatingsDataset(x_train.reset_index(drop = True), y_train.reset_index(drop = True))\n",
    "        ValDataset = RatingsDataset(x_test.reset_index(drop = True), y_test.reset_index(drop = True))\n",
    "        \n",
    "        dataloader_train = DataLoader(TrainDataset, \n",
    "                                  collate_fn=RatingsDataset.collate, \n",
    "                                  batch_size=batch_size, shuffle=True, drop_last=True, \n",
    "                                  num_workers=4, pin_memory=True)\n",
    "\n",
    "        dataloader_val = DataLoader(ValDataset, \n",
    "                                collate_fn=RatingsDataset.collate, \n",
    "                                batch_size=batch_size, shuffle=False, drop_last=False, \n",
    "                                num_workers=4, pin_memory=True)\n",
    "        \n",
    "        models_KFold[i] = NeuMF(n_users, n_items, n_factors_mf = k, n_factors_mlp = k, hidden_layers_sizes = [16, 16], \n",
    "              activation = True, dropouts_mlp = [0.9,0.9], dropout_mf = 0.5)\n",
    "\n",
    "        optimizer = torch.optim.Adam(models_KFold[i].parameters(), lr = lr)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)\n",
    "        \n",
    "        train_losses, val_losses, best_val_loss, models_KFold[i] = run_experiment(\n",
    "        models_KFold[i], dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints/\")\n",
    "        \n",
    "        train_losses_KFold.append(train_losses[-1])\n",
    "        val_losses_KFold.append(best_val_loss)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    mean_KFold_losses.append(np.mean(val_losses_KFold))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bj5Td7Jwj55i",
   "metadata": {
    "id": "Bj5Td7Jwj55i"
   },
   "source": [
    "Посмотрим на средние значения RMSE по фолдам для 8, 10 и 12 факторов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aFyRk2mPj55i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFyRk2mPj55i",
    "outputId": "0f11899e-907d-4343-da2f-5e767f36ab61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0651523080641137, 2.066052587813141, 2.065395067926397]\n"
     ]
    }
   ],
   "source": [
    "print(mean_KFold_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UiOvgqzoj55i",
   "metadata": {
    "id": "UiOvgqzoj55i"
   },
   "source": [
    "Видим, что наилучшее качество получилось для модели с 8 факторами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QF-FtYWVA7Ra",
   "metadata": {
    "id": "QF-FtYWVA7Ra"
   },
   "source": [
    "## 3. Гибридная архитектура"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vMDHwh3rHFrT",
   "metadata": {
    "id": "vMDHwh3rHFrT"
   },
   "source": [
    "Добавим в модель признаков, усложним архитектору и объединим всё получивщееся в одно предсказание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd83457",
   "metadata": {
    "id": "bdd83457"
   },
   "source": [
    "`transactions.csv` — список всех транзакций за определённый период времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67336667",
   "metadata": {
    "id": "67336667"
   },
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('/content/drive/MyDrive/AI Masters/transactions.csv',\n",
    "    dtype={\n",
    "        'element_uid': np.uint16,\n",
    "        'user_uid': np.uint32,\n",
    "        'consumption_mode': 'category',\n",
    "        'ts': np.float64,\n",
    "        'watched_time': np.uint64,\n",
    "        'device_type': np.uint8,\n",
    "        'device_manufacturer': np.uint8\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b31bd836",
   "metadata": {
    "id": "b31bd836"
   },
   "outputs": [],
   "source": [
    "transactions.rename(columns = {'user_uid':'user_id', 'element_uid':'item_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3dff9",
   "metadata": {
    "id": "ebd3dff9"
   },
   "source": [
    " - `item_id` — идентификатор элемента\n",
    " - `user_id` — идентификатор пользователя\n",
    " - `consumption_mode` — тип потребления (`P` — покупка, `R` — аренда, `S` — просмотр по подписке)\n",
    " - `ts` — время совершения транзакции или начала просмотра в случае просмотра по подписке\n",
    " - `watched_time` — число просмотренных по транзакции секунд\n",
    " - `device_type` — анонимизированный тип устройства, с которого была совершена транзакция или начат просмотр\n",
    " - `device_manufacturer` — анонимизированный производитель устройства, с которого была совершена транзакция или начат просмотр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a8dfa27",
   "metadata": {
    "id": "1a8dfa27"
   },
   "outputs": [],
   "source": [
    "transactions['user_id'] = u_enc.fit_transform(transactions['user_id'])\n",
    "transactions['item_id'] = i_enc.fit_transform(transactions['item_id'])\n",
    "\n",
    "transactions.sort_values('ts', inplace = True)\n",
    "transactions.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d81fa40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4d81fa40",
    "outputId": "2d70a45e-eca0-48d4-f8ea-d826bcb8d466"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-dcedf39e-5eda-42e8-8e46-9d6b90e51a03\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>consumption_mode</th>\n",
       "      <th>ts</th>\n",
       "      <th>watched_time</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_manufacturer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5021</td>\n",
       "      <td>238768</td>\n",
       "      <td>S</td>\n",
       "      <td>4.173063e+07</td>\n",
       "      <td>19586</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4946</td>\n",
       "      <td>49740</td>\n",
       "      <td>S</td>\n",
       "      <td>4.173063e+07</td>\n",
       "      <td>6831</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7221</td>\n",
       "      <td>42432</td>\n",
       "      <td>S</td>\n",
       "      <td>4.173063e+07</td>\n",
       "      <td>5763</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6847</td>\n",
       "      <td>386167</td>\n",
       "      <td>S</td>\n",
       "      <td>4.173063e+07</td>\n",
       "      <td>8360</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1807</td>\n",
       "      <td>152191</td>\n",
       "      <td>S</td>\n",
       "      <td>4.173063e+07</td>\n",
       "      <td>2503</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcedf39e-5eda-42e8-8e46-9d6b90e51a03')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-dcedf39e-5eda-42e8-8e46-9d6b90e51a03 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-dcedf39e-5eda-42e8-8e46-9d6b90e51a03');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   item_id  user_id consumption_mode            ts  watched_time  device_type  \\\n",
       "0     5021   238768                S  4.173063e+07         19586            0   \n",
       "1     4946    49740                S  4.173063e+07          6831            0   \n",
       "2     7221    42432                S  4.173063e+07          5763            0   \n",
       "3     6847   386167                S  4.173063e+07          8360            0   \n",
       "4     1807   152191                S  4.173063e+07          2503            0   \n",
       "\n",
       "   device_manufacturer  \n",
       "0                   11  \n",
       "1                   50  \n",
       "2                   11  \n",
       "3                   50  \n",
       "4                   11  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "667ce9fb",
   "metadata": {
    "id": "667ce9fb"
   },
   "outputs": [],
   "source": [
    "dataframe.set_index('user_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f61ab2e1",
   "metadata": {
    "id": "f61ab2e1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "devices_number = transactions.groupby('user_id')['device_type'].nunique()\n",
    "devices_number = devices_number.rename('devices_number')\n",
    "dataframe = dataframe.join(devices_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43e43d80",
   "metadata": {
    "id": "43e43d80"
   },
   "outputs": [],
   "source": [
    "mean_watched_time = transactions.groupby('user_id')['watched_time'].mean() \n",
    "mean_watched_time = mean_watched_time.rename('mean_watched_time')\n",
    "dataframe = dataframe.join(mean_watched_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2240be8e",
   "metadata": {
    "id": "2240be8e"
   },
   "outputs": [],
   "source": [
    "number_of_actions = transactions.groupby('user_id')['consumption_mode'].count()\n",
    "number_of_actions = number_of_actions.rename('number_of_actions')\n",
    "dataframe = dataframe.join(number_of_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8661166e",
   "metadata": {
    "id": "8661166e"
   },
   "outputs": [],
   "source": [
    "dataframe.sort_values('ts', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f12fda3e",
   "metadata": {
    "id": "f12fda3e"
   },
   "outputs": [],
   "source": [
    "dataframe.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "mwfk_XdMwAkH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mwfk_XdMwAkH",
    "outputId": "d91beb01-688a-4a35-9410-efb0ff88b0d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a04dd75a-9a97-4753-842e-d6a93af8e894\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>ts</th>\n",
       "      <th>devices_number</th>\n",
       "      <th>mean_watched_time</th>\n",
       "      <th>number_of_actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65882</td>\n",
       "      <td>6586</td>\n",
       "      <td>2</td>\n",
       "      <td>4.173065e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>5434.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86840</td>\n",
       "      <td>5912</td>\n",
       "      <td>7</td>\n",
       "      <td>4.173078e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>7635.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62263</td>\n",
       "      <td>2443</td>\n",
       "      <td>8</td>\n",
       "      <td>4.173079e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>15358.627737</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5710</td>\n",
       "      <td>4521</td>\n",
       "      <td>8</td>\n",
       "      <td>4.173085e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>2887.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30028</td>\n",
       "      <td>1110</td>\n",
       "      <td>8</td>\n",
       "      <td>4.173086e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>2741.200000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a04dd75a-9a97-4753-842e-d6a93af8e894')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a04dd75a-9a97-4753-842e-d6a93af8e894 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a04dd75a-9a97-4753-842e-d6a93af8e894');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   user_id  item_id  rating            ts  devices_number  mean_watched_time  \\\n",
       "0    65882     6586       2  4.173065e+07               1        5434.000000   \n",
       "1    86840     5912       7  4.173078e+07               1        7635.500000   \n",
       "2    62263     2443       8  4.173079e+07               2       15358.627737   \n",
       "3     5710     4521       8  4.173085e+07               1        2887.000000   \n",
       "4    30028     1110       8  4.173086e+07               1        2741.200000   \n",
       "\n",
       "   number_of_actions  \n",
       "0                  6  \n",
       "1                  4  \n",
       "2                137  \n",
       "3                  4  \n",
       "4                 10  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "TSbX5R5lxE9c",
   "metadata": {
    "id": "TSbX5R5lxE9c"
   },
   "outputs": [],
   "source": [
    "bookmarks = pd.read_csv('/content/drive/MyDrive/AI Masters/bookmarks.csv',\n",
    "    dtype={\n",
    "        'element_uid': np.uint16,\n",
    "        'user_uid': np.uint32,\n",
    "        'ts': np.float64\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuatRjo43_fM",
   "metadata": {
    "id": "fuatRjo43_fM"
   },
   "source": [
    "`bookmarks.csv` содержит информацию об элементах, добавленных пользователями в список «Избранное»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "UmoOzsex1CcF",
   "metadata": {
    "id": "UmoOzsex1CcF"
   },
   "outputs": [],
   "source": [
    "bookmarks.rename(columns = {'user_uid':'user_id', 'element_uid':'item_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "lQSn75ShxL0W",
   "metadata": {
    "id": "lQSn75ShxL0W"
   },
   "outputs": [],
   "source": [
    "bookmarks['user_id'] = u_enc.fit_transform(bookmarks['user_id'])\n",
    "bookmarks['item_id'] = i_enc.fit_transform(bookmarks['item_id'])\n",
    "\n",
    "bookmarks.sort_values('ts', inplace = True)\n",
    "bookmarks.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8tj6kgpP4vhc",
   "metadata": {
    "id": "8tj6kgpP4vhc"
   },
   "source": [
    "Выберем среди объектов те, которые пользователи добавили в \"Избранное\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "HX8AFCxPxL3C",
   "metadata": {
    "id": "HX8AFCxPxL3C"
   },
   "outputs": [],
   "source": [
    "bookmarks = bookmarks.drop(columns = ['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "wdz9x09mxL5m",
   "metadata": {
    "id": "wdz9x09mxL5m"
   },
   "outputs": [],
   "source": [
    "bookmarks['is_favorites'] = 1\n",
    "\n",
    "dataframe = pd.merge(dataframe, bookmarks, how='left', on=['user_id', 'item_id'])\n",
    "\n",
    "dataframe = dataframe.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "xhmnvdfAxL8W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xhmnvdfAxL8W",
    "outputId": "ca89cb24-5c9a-4fa7-a367-4e76f55cf31f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b6e240c2-fa26-4842-86b1-eb4091b04624\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>ts</th>\n",
       "      <th>devices_number</th>\n",
       "      <th>mean_watched_time</th>\n",
       "      <th>number_of_actions</th>\n",
       "      <th>is_favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65882</td>\n",
       "      <td>6586</td>\n",
       "      <td>2</td>\n",
       "      <td>4.173065e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>5434.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86840</td>\n",
       "      <td>5912</td>\n",
       "      <td>7</td>\n",
       "      <td>4.173078e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>7635.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62263</td>\n",
       "      <td>2443</td>\n",
       "      <td>8</td>\n",
       "      <td>4.173079e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>15358.627737</td>\n",
       "      <td>137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5710</td>\n",
       "      <td>4521</td>\n",
       "      <td>8</td>\n",
       "      <td>4.173085e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>2887.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30028</td>\n",
       "      <td>1110</td>\n",
       "      <td>8</td>\n",
       "      <td>4.173086e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>2741.200000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6e240c2-fa26-4842-86b1-eb4091b04624')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b6e240c2-fa26-4842-86b1-eb4091b04624 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b6e240c2-fa26-4842-86b1-eb4091b04624');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   user_id  item_id  rating            ts  devices_number  mean_watched_time  \\\n",
       "0    65882     6586       2  4.173065e+07               1        5434.000000   \n",
       "1    86840     5912       7  4.173078e+07               1        7635.500000   \n",
       "2    62263     2443       8  4.173079e+07               2       15358.627737   \n",
       "3     5710     4521       8  4.173085e+07               1        2887.000000   \n",
       "4    30028     1110       8  4.173086e+07               1        2741.200000   \n",
       "\n",
       "   number_of_actions  is_favorites  \n",
       "0                  6           0.0  \n",
       "1                  4           0.0  \n",
       "2                137           0.0  \n",
       "3                  4           0.0  \n",
       "4                 10           0.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836d6c3",
   "metadata": {
    "id": "2836d6c3"
   },
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa95d6b0",
   "metadata": {
    "id": "fa95d6b0"
   },
   "outputs": [],
   "source": [
    "class RatingsDatasetWithFeatures(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y=None):\n",
    "\n",
    "        self.users = X.user_id\n",
    "        self.items = X.item_id\n",
    "        self.ratings = y\n",
    "        # добавили признаки\n",
    "        self.another_features = X.drop(columns = ['user_id','item_id']).values\n",
    "        \n",
    "    def __len__(self,):\n",
    "\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        return self.users[i], self.items[i], self.ratings[i], self.another_features[i]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate(batch):\n",
    "\n",
    "        users = torch.tensor([elem[0] for elem in batch])\n",
    "        items = torch.tensor([elem[1] for elem in batch])\n",
    "        ratings = torch.tensor([elem[2] for elem in batch])    \n",
    "        another_features = torch.tensor([elem[3] for elem in batch])\n",
    "        \n",
    "        return users, items, ratings, another_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "v736KeKk8b3w",
   "metadata": {
    "id": "v736KeKk8b3w"
   },
   "outputs": [],
   "source": [
    "class NeuMF_hybrid(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors_mf, n_factors_mlp, num_features, hidden_layers_sizes_mlp, hidden_layers_sizes_features, activation, dropouts_mlp, dropout_mf, dropouts_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_factors_mf = n_factors_mf\n",
    "        self.n_factors_mlp = n_factors_mlp\n",
    "        self.num_features = num_features\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.p = dropout_mf\n",
    "        self.dropouts_mlp = dropouts_mlp\n",
    "        self.dropouts_features = dropouts_features\n",
    "    \n",
    "        # mf part\n",
    "        self.u_emb_mf = nn.Embedding(self.n_users, self.n_factors_mf)\n",
    "        self.i_emb_mf = nn.Embedding(self.n_items, self.n_factors_mf)\n",
    "\n",
    "        self.dropout_mf = torch.nn.Dropout(self.p)\n",
    "        \n",
    "        # mlp part\n",
    "        self.u_emb_mlp = nn.Embedding(self.n_users, self.n_factors_mlp)\n",
    "        self.i_emb_mlp = nn.Embedding(self.n_items, self.n_factors_mlp)\n",
    "        \n",
    "        \n",
    "        layers_mlp = [Block(2*n_factors_mlp, hidden_layers_sizes_mlp[0], activation = activation, dropout = dropouts_mlp[0])]\n",
    "        \n",
    "        for i in range(len(hidden_layers_sizes_mlp)-1):\n",
    "            layers_mlp.append(Block(hidden_layers_sizes_mlp[i], hidden_layers_sizes_mlp[i+1], activation = activation, dropout = dropouts_mlp[i+1]))\n",
    "              \n",
    "        self.mlp = nn.Sequential(*layers_mlp)\n",
    "\n",
    "        # extra features part\n",
    "\n",
    "        layers_ef = [Block(num_features, hidden_layers_sizes_features[0], activation = activation, dropout = dropouts_features[0])]\n",
    "        \n",
    "        for i in range(len(hidden_layers_sizes_features)-1):\n",
    "            layers_ef.append(Block(hidden_layers_sizes_features[i], hidden_layers_sizes_features[i+1], activation = activation, dropout = dropouts_features[i+1]))\n",
    "              \n",
    "        self.ef = nn.Sequential(*layers_ef)\n",
    "\n",
    "\n",
    "        self.out_linear = torch.nn.Linear(in_features = hidden_layers_sizes_mlp[-1] + self.n_factors_mf + hidden_layers_sizes_features[-1], out_features = 1)\n",
    "\n",
    "    def forward(self, users, items, extra_features): \n",
    "        \n",
    "        features_mf = torch.mul(self.u_emb_mf(users), self.i_emb_mf(items))\n",
    "        features_mlp = torch.cat([self.u_emb_mlp(users), self.i_emb_mlp(items)], dim=-1)\n",
    "\n",
    "        out_mlp = self.mlp(features_mlp)\n",
    "        out_mf = self.dropout_mf(features_mf)\n",
    "        out_ef = self.ef(extra_features.float())\n",
    "\n",
    "        out = torch.cat([out_mlp, out_mf, out_ef], dim=-1)\n",
    "        return self.out_linear(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4JROYf8T_4HN",
   "metadata": {
    "id": "4JROYf8T_4HN"
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c58d4da0",
   "metadata": {
    "id": "c58d4da0"
   },
   "outputs": [],
   "source": [
    "def run_epoch_modern(stage, model, dataloader, loss_fn, optimizer, epoch, device):\n",
    "    \n",
    "    if stage == \"train\":\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.eval()\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc=f\"epoch: {str(epoch).zfill(3)} | {stage:5}\"):\n",
    "        us, its, ys_true, feats = batch\n",
    "                \n",
    "        ys_pred = model(us.to(device), its.to(device), feats.to(device))\n",
    "        loss = loss_fn(ys_pred, ys_true.to(device))\n",
    "\n",
    "        if stage == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        losses.append(loss.detach().cpu().item())\n",
    "    if stage == \"train\":\n",
    "        scheduler.step(np.mean(losses))\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3edd000",
   "metadata": {
    "id": "d3edd000"
   },
   "outputs": [],
   "source": [
    "def run_experiment_modern(model, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, output_dir):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    best_val_loss_epoch = -1\n",
    "    best_val_loss_fn = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = run_epoch_modern(\"train\", model, dataloader_train, loss_fn, optimizer, epoch, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss = run_epoch_modern(\"val\", model, dataloader_val, loss_fn, optimizer, epoch, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"epoch: {str(epoch).zfill(3)} | train_loss: {train_loss:5.3f}, val_loss: {val_loss:5.3f} (best: {best_val_loss:5.3f})\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "\n",
    "            best_val_loss = val_loss\n",
    "            best_val_loss_epoch = epoch\n",
    "\n",
    "            #output_fn = os.path.join(output_dir, f\"epoch={str(epoch).zfill(2)}_valloss={best_val_loss:.3f}.pth.tar\")\n",
    "            #save_checkpoint(model, output_fn)\n",
    "            #print(f\"New checkpoint saved to {output_fn}\")\n",
    "\n",
    "            #best_val_loss_fn = output_fn\n",
    "\n",
    "        print()\n",
    "\n",
    "    print (f\"Best val_loss = {best_val_loss:.3f} reached at epoch {best_val_loss_epoch}\")\n",
    "    #load_checkpoint(model, best_val_loss_fn)\n",
    "\n",
    "    return train_losses, val_losses, best_val_loss, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7WE7VsOu_vw_",
   "metadata": {
    "id": "7WE7VsOu_vw_"
   },
   "source": [
    "Проверим, что модель обучается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "LLblUYQ-ABV9",
   "metadata": {
    "id": "LLblUYQ-ABV9"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataframe.drop(columns = ['rating','ts']), dataframe.rating, test_size=0.2, random_state=42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "uUomazyz_vxA",
   "metadata": {
    "id": "uUomazyz_vxA"
   },
   "outputs": [],
   "source": [
    "TrainDataset = RatingsDatasetWithFeatures(X_train, y_train)\n",
    "ValDataset = RatingsDatasetWithFeatures(X_test.reset_index(drop = True), y_test.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cGmC9No7_vxA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGmC9No7_vxA",
    "outputId": "a37c07d4-4e20-4dbb-ea44-ec34ab8b265f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "lr = 3e-4\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "xWF7rgxR_vxB",
   "metadata": {
    "id": "xWF7rgxR_vxB"
   },
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(TrainDataset, \n",
    "                              collate_fn=RatingsDatasetWithFeatures.collate, \n",
    "                              batch_size=batch_size, shuffle=True, drop_last=True, \n",
    "                              num_workers=4, pin_memory=True)\n",
    "\n",
    "dataloader_val = DataLoader(ValDataset, \n",
    "                            collate_fn=RatingsDatasetWithFeatures.collate, \n",
    "                            batch_size=batch_size, shuffle=False, drop_last=False, \n",
    "                            num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "OneEPfDJA6nQ",
   "metadata": {
    "id": "OneEPfDJA6nQ"
   },
   "outputs": [],
   "source": [
    "num_features = len(X_train.columns) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0JM1LJkl_vxB",
   "metadata": {
    "id": "0JM1LJkl_vxB"
   },
   "outputs": [],
   "source": [
    "model = NeuMF_hybrid(n_users, n_items, n_factors_mf = 5, n_factors_mlp = 5, num_features = num_features, \n",
    "                     hidden_layers_sizes_mlp = [16, 16], hidden_layers_sizes_features = [16, 16], activation = True, \n",
    "                     dropouts_mlp = [0.9,0.9], dropout_mf = 0.5, dropouts_features = [0.9,0.9])\n",
    "loss_fn = RMSELoss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "jJLn4VnQ_vxB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJLn4VnQ_vxB",
    "outputId": "f4ffb1dd-28be-4cb5-ba4f-d6e84977f4a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/2742 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 2742/2742 [01:30<00:00, 30.42it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/686 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 686/686 [00:04<00:00, 160.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 117.444, val_loss: 4.617 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/2742 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 2742/2742 [01:50<00:00, 24.89it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/686 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 686/686 [00:03<00:00, 178.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 4.667, val_loss: 3.401 (best: 4.617)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/2742 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 2742/2742 [01:50<00:00, 24.89it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/686 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  :   0%|          | 1/686 [00:00<01:36,  7.11it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 686/686 [00:03<00:00, 179.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 4.140, val_loss: 3.116 (best: 3.401)\n",
      "\n",
      "Best val_loss = 3.116 reached at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, best_val_loss, model = run_experiment_modern(\n",
    "    model, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3MCNdp1Da1o",
   "metadata": {
    "id": "c3MCNdp1Da1o"
   },
   "source": [
    "### Валидация модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sZ3zAqrBGYAS",
   "metadata": {
    "id": "sZ3zAqrBGYAS"
   },
   "source": [
    "В силу большой вычислительной сложности проведём валидацию параметра n_factors на большем размере батчей и небольшом количестве эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "rSpFsq0tDa1p",
   "metadata": {
    "id": "rSpFsq0tDa1p"
   },
   "outputs": [],
   "source": [
    "num_epochs = 7\n",
    "batch_size = 2048\n",
    "lr = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "RBI4cnDGDa1p",
   "metadata": {
    "id": "RBI4cnDGDa1p"
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "g7MwIJcdDa1p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7MwIJcdDa1p",
    "outputId": "3b20d3c1-74af-40d6-d743-048595d8d47f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 142/142 [00:12<00:00, 11.60it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 72/72 [00:03<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 2014.566, val_loss: 99.962 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 142/142 [00:15<00:00,  9.46it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 72/72 [00:03<00:00, 18.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 1190.948, val_loss: 23.396 (best: 99.962)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 142/142 [00:17<00:00,  8.21it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 72/72 [00:03<00:00, 21.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 698.961, val_loss: 11.376 (best: 23.396)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 003 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | train: 100%|██████████| 142/142 [00:13<00:00, 10.42it/s]\n",
      "epoch: 003 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 432.571, val_loss: 6.969 (best: 11.376)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 004 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | train: 100%|██████████| 142/142 [00:11<00:00, 12.19it/s]\n",
      "epoch: 004 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 206.421, val_loss: 7.151 (best: 6.969)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 005 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | train: 100%|██████████| 142/142 [00:11<00:00, 12.23it/s]\n",
      "epoch: 005 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | val  : 100%|██████████| 72/72 [00:03<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 81.890, val_loss: 7.792 (best: 6.969)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 006 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | train: 100%|██████████| 142/142 [00:15<00:00,  9.20it/s]\n",
      "epoch: 006 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | val  : 100%|██████████| 72/72 [00:03<00:00, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 21.860, val_loss: 7.138 (best: 6.969)\n",
      "\n",
      "Best val_loss = 6.969 reached at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 142/142 [00:19<00:00,  7.27it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 72/72 [00:03<00:00, 20.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 1090.856, val_loss: 6.922 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 142/142 [00:16<00:00,  8.68it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 72/72 [00:03<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 505.576, val_loss: 9.857 (best: 6.922)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 142/142 [00:15<00:00,  9.21it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 72/72 [00:03<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 229.101, val_loss: 6.258 (best: 6.922)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 003 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | train: 100%|██████████| 142/142 [00:14<00:00,  9.67it/s]\n",
      "epoch: 003 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | val  : 100%|██████████| 72/72 [00:03<00:00, 21.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 87.301, val_loss: 6.932 (best: 6.258)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 004 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | train: 100%|██████████| 142/142 [00:13<00:00, 10.20it/s]\n",
      "epoch: 004 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | val  : 100%|██████████| 72/72 [00:03<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 27.195, val_loss: 6.416 (best: 6.258)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 005 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | train: 100%|██████████| 142/142 [00:15<00:00,  9.28it/s]\n",
      "epoch: 005 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | val  : 100%|██████████| 72/72 [00:04<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 11.261, val_loss: 5.942 (best: 6.258)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 006 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | train: 100%|██████████| 142/142 [00:15<00:00,  9.19it/s]\n",
      "epoch: 006 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | val  : 100%|██████████| 72/72 [00:03<00:00, 18.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 9.744, val_loss: 5.534 (best: 5.942)\n",
      "\n",
      "Best val_loss = 5.534 reached at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 142/142 [00:13<00:00, 10.52it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 3511.635, val_loss: 112.671 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 142/142 [00:12<00:00, 11.53it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  :   1%|▏         | 1/72 [00:00<00:28,  2.52it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 2234.096, val_loss: 47.073 (best: 112.671)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 142/142 [00:17<00:00,  8.12it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 72/72 [00:03<00:00, 19.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 1393.062, val_loss: 32.065 (best: 47.073)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 003 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | train: 100%|██████████| 142/142 [00:14<00:00, 10.11it/s]\n",
      "epoch: 003 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 826.947, val_loss: 15.305 (best: 32.065)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 004 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | train: 100%|██████████| 142/142 [00:12<00:00, 11.76it/s]\n",
      "epoch: 004 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | val  : 100%|██████████| 72/72 [00:03<00:00, 19.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 459.926, val_loss: 16.698 (best: 15.305)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 005 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | train: 100%|██████████| 142/142 [00:13<00:00, 10.27it/s]\n",
      "epoch: 005 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 186.020, val_loss: 8.567 (best: 15.305)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 006 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | train: 100%|██████████| 142/142 [00:11<00:00, 11.90it/s]\n",
      "epoch: 006 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 50.690, val_loss: 5.907 (best: 8.567)\n",
      "\n",
      "Best val_loss = 5.907 reached at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 142/142 [00:13<00:00, 10.65it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 821.158, val_loss: 53.990 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 142/142 [00:18<00:00,  7.75it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 72/72 [00:04<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 438.487, val_loss: 39.126 (best: 53.990)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 142/142 [00:22<00:00,  6.43it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 72/72 [00:04<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 245.195, val_loss: 27.084 (best: 39.126)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 003 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | train: 100%|██████████| 142/142 [00:15<00:00,  9.21it/s]\n",
      "epoch: 003 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | val  : 100%|██████████| 72/72 [00:04<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 147.638, val_loss: 15.940 (best: 27.084)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 004 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | train: 100%|██████████| 142/142 [00:16<00:00,  8.74it/s]\n",
      "epoch: 004 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | val  : 100%|██████████| 72/72 [00:03<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 74.313, val_loss: 10.888 (best: 15.940)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 005 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | train: 100%|██████████| 142/142 [00:15<00:00,  9.22it/s]\n",
      "epoch: 005 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | val  : 100%|██████████| 72/72 [00:04<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 29.715, val_loss: 7.843 (best: 10.888)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 006 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | train: 100%|██████████| 142/142 [00:17<00:00,  8.25it/s]\n",
      "epoch: 006 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | val  : 100%|██████████| 72/72 [00:04<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 10.390, val_loss: 6.727 (best: 7.843)\n",
      "\n",
      "Best val_loss = 6.727 reached at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 142/142 [00:16<00:00,  8.75it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 72/72 [00:03<00:00, 19.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 986.792, val_loss: 15.331 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 142/142 [00:18<00:00,  7.68it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 72/72 [00:04<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 505.419, val_loss: 12.630 (best: 15.331)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 142/142 [00:15<00:00,  9.09it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 279.792, val_loss: 9.415 (best: 12.630)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 003 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | train: 100%|██████████| 142/142 [00:13<00:00, 10.16it/s]\n",
      "epoch: 003 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 137.455, val_loss: 9.114 (best: 9.415)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 004 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | train: 100%|██████████| 142/142 [00:13<00:00, 10.69it/s]\n",
      "epoch: 004 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 70.340, val_loss: 8.881 (best: 9.114)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 005 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | train: 100%|██████████| 142/142 [00:13<00:00, 10.79it/s]\n",
      "epoch: 005 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 35.230, val_loss: 8.508 (best: 8.881)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 006 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | train: 100%|██████████| 142/142 [00:13<00:00, 10.57it/s]\n",
      "epoch: 006 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 15.999, val_loss: 7.950 (best: 8.508)\n",
      "\n",
      "Best val_loss = 7.950 reached at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 142/142 [00:13<00:00, 10.72it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 1690.352, val_loss: 68.620 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 142/142 [00:13<00:00, 10.87it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 970.672, val_loss: 37.530 (best: 68.620)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 142/142 [00:12<00:00, 11.26it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 486.651, val_loss: 16.285 (best: 37.530)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 003 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | train: 100%|██████████| 142/142 [00:14<00:00,  9.67it/s]\n",
      "epoch: 003 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 251.877, val_loss: 6.735 (best: 16.285)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 004 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | train: 100%|██████████| 142/142 [00:12<00:00, 11.23it/s]\n",
      "epoch: 004 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | val  : 100%|██████████| 72/72 [00:03<00:00, 23.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 72.439, val_loss: 7.822 (best: 6.735)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 005 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | train: 100%|██████████| 142/142 [00:17<00:00,  7.94it/s]\n",
      "epoch: 005 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 10.198, val_loss: 6.639 (best: 6.735)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 006 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | train: 100%|██████████| 142/142 [00:12<00:00, 11.09it/s]\n",
      "epoch: 006 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 8.544, val_loss: 5.928 (best: 6.639)\n",
      "\n",
      "Best val_loss = 5.928 reached at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 142/142 [00:14<00:00, 10.06it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 2123.288, val_loss: 68.575 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 142/142 [00:13<00:00, 10.24it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 1284.083, val_loss: 25.563 (best: 68.575)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 142/142 [00:13<00:00, 10.51it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 800.188, val_loss: 11.527 (best: 25.563)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 003 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | train: 100%|██████████| 142/142 [00:13<00:00, 10.66it/s]\n",
      "epoch: 003 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | val  : 100%|██████████| 72/72 [00:03<00:00, 23.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 461.806, val_loss: 6.990 (best: 11.527)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 004 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | train: 100%|██████████| 142/142 [00:13<00:00, 10.58it/s]\n",
      "epoch: 004 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | val  : 100%|██████████| 72/72 [00:02<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 254.027, val_loss: 7.355 (best: 6.990)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 005 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | train: 100%|██████████| 142/142 [00:13<00:00, 10.47it/s]\n",
      "epoch: 005 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | val  : 100%|██████████| 72/72 [00:03<00:00, 23.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 108.594, val_loss: 8.502 (best: 6.990)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 006 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | train: 100%|██████████| 142/142 [00:13<00:00, 10.34it/s]\n",
      "epoch: 006 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | val  : 100%|██████████| 72/72 [00:03<00:00, 23.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 35.636, val_loss: 7.485 (best: 6.990)\n",
      "\n",
      "Best val_loss = 6.990 reached at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 142/142 [00:18<00:00,  7.89it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 72/72 [00:04<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 661.785, val_loss: 30.978 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 142/142 [00:18<00:00,  7.83it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 72/72 [00:04<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 264.900, val_loss: 13.807 (best: 30.978)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 142/142 [00:17<00:00,  8.00it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 72/72 [00:03<00:00, 18.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 60.851, val_loss: 7.510 (best: 13.807)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 003 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | train: 100%|██████████| 142/142 [00:17<00:00,  7.98it/s]\n",
      "epoch: 003 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | val  : 100%|██████████| 72/72 [00:04<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 8.537, val_loss: 6.481 (best: 7.510)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 004 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | train: 100%|██████████| 142/142 [00:17<00:00,  8.09it/s]\n",
      "epoch: 004 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | val  : 100%|██████████| 72/72 [00:03<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 7.177, val_loss: 5.869 (best: 6.481)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 005 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | train: 100%|██████████| 142/142 [00:17<00:00,  8.21it/s]\n",
      "epoch: 005 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | val  : 100%|██████████| 72/72 [00:03<00:00, 23.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 6.634, val_loss: 5.464 (best: 5.869)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 006 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | train: 100%|██████████| 142/142 [00:21<00:00,  6.46it/s]\n",
      "epoch: 006 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | val  : 100%|██████████| 72/72 [00:03<00:00, 19.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 6.364, val_loss: 5.084 (best: 5.464)\n",
      "\n",
      "Best val_loss = 5.084 reached at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 000 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | train: 100%|██████████| 142/142 [00:19<00:00,  7.21it/s]\n",
      "epoch: 000 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 000 | val  : 100%|██████████| 72/72 [00:03<00:00, 19.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 643.419, val_loss: 43.506 (best:   inf)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 001 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | train: 100%|██████████| 142/142 [00:19<00:00,  7.16it/s]\n",
      "epoch: 001 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 001 | val  : 100%|██████████| 72/72 [00:03<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 271.308, val_loss: 16.334 (best: 43.506)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 002 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | train: 100%|██████████| 142/142 [00:15<00:00,  9.25it/s]\n",
      "epoch: 002 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 002 | val  : 100%|██████████| 72/72 [00:03<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 98.116, val_loss: 8.119 (best: 16.334)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 003 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | train: 100%|██████████| 142/142 [00:18<00:00,  7.69it/s]\n",
      "epoch: 003 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 003 | val  : 100%|██████████| 72/72 [00:03<00:00, 18.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 26.896, val_loss: 7.261 (best: 8.119)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 004 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | train: 100%|██████████| 142/142 [00:18<00:00,  7.62it/s]\n",
      "epoch: 004 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 004 | val  : 100%|██████████| 72/72 [00:04<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 10.748, val_loss: 6.326 (best: 7.261)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 005 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | train: 100%|██████████| 142/142 [00:18<00:00,  7.71it/s]\n",
      "epoch: 005 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 005 | val  : 100%|██████████| 72/72 [00:03<00:00, 18.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 7.599, val_loss: 5.771 (best: 6.326)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 006 | train:   0%|          | 0/142 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | train: 100%|██████████| 142/142 [00:18<00:00,  7.69it/s]\n",
      "epoch: 006 | val  :   0%|          | 0/72 [00:00<?, ?it/s]<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "<ipython-input-51-b9ba253be7fd>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  another_features = torch.tensor([elem[3] for elem in batch])\n",
      "epoch: 006 | val  : 100%|██████████| 72/72 [00:03<00:00, 19.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 6.535, val_loss: 5.249 (best: 5.771)\n",
      "\n",
      "Best val_loss = 5.249 reached at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_KFold_losses = []\n",
    "for k in [8, 10, 12]:\n",
    "    val_losses_KFold = []\n",
    "    train_losses_KFold = []\n",
    "    models_KFold = list(np.zeros(cv.get_n_splits()))\n",
    "    i = 0\n",
    "\n",
    "    for train_index, test_index in cv.split(dataframe.drop(columns = ['rating','ts'])):\n",
    "        x_train, x_test = dataframe.drop(columns = ['rating','ts']).iloc[train_index], dataframe.drop(columns = ['rating','ts']).iloc[test_index]\n",
    "        y_train, y_test = dataframe['rating'].iloc[train_index], dataframe['rating'].iloc[test_index]\n",
    "        \n",
    "        TrainDataset = RatingsDatasetWithFeatures(x_train.reset_index(drop = True), y_train.reset_index(drop = True))\n",
    "        ValDataset = RatingsDatasetWithFeatures(x_test.reset_index(drop = True), y_test.reset_index(drop = True))\n",
    "        \n",
    "        dataloader_train = DataLoader(TrainDataset, \n",
    "                                  collate_fn=RatingsDatasetWithFeatures.collate, \n",
    "                                  batch_size=batch_size, shuffle=True, drop_last=True, \n",
    "                                  num_workers=4, pin_memory=True)\n",
    "\n",
    "        dataloader_val = DataLoader(ValDataset, \n",
    "                                collate_fn=RatingsDatasetWithFeatures.collate, \n",
    "                                batch_size=batch_size, shuffle=False, drop_last=False, \n",
    "                                num_workers=4, pin_memory=True)\n",
    "        \n",
    "        models_KFold[i] = NeuMF_hybrid(n_users, n_items, n_factors_mf = k, n_factors_mlp = k, num_features = num_features, \n",
    "                     hidden_layers_sizes_mlp = [16, 16], hidden_layers_sizes_features = [16, 16], activation = True, \n",
    "                     dropouts_mlp = [0.9,0.9], dropout_mf = 0.5, dropouts_features = [0.9,0.9])\n",
    "\n",
    "        optimizer = torch.optim.Adam(models_KFold[i].parameters(), lr = lr)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)\n",
    "        \n",
    "        train_losses, val_losses, best_val_loss, models_KFold[i] = run_experiment_modern(\n",
    "        models_KFold[i], dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints/\")\n",
    "        \n",
    "        train_losses_KFold.append(train_losses[-1])\n",
    "        val_losses_KFold.append(best_val_loss)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    mean_KFold_losses.append(np.mean(val_losses_KFold))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uc5PUsBgDa1q",
   "metadata": {
    "id": "uc5PUsBgDa1q"
   },
   "source": [
    "Посмотрим на средние значения RMSE по фолдам для 8, 10 и 12 факторов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "q4IhVhiiDa1q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4IhVhiiDa1q",
    "outputId": "3cfc6fb7-8680-4684-a17f-db83e8e49b37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1366508294034885, 6.86840220954683, 5.774544821845161]\n"
     ]
    }
   ],
   "source": [
    "print(mean_KFold_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ei0EJzsJLLdF",
   "metadata": {
    "id": "ei0EJzsJLLdF"
   },
   "source": [
    "Заметим, что, как и предполагалось, модели не успели обучиться за такое небольшое число эпох, однако мы всё равно можем сделать вывод о лучшем количестве параметра n_factors. Так что сами величины ошибок не репрезентативны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wo4k0ToJDa1q",
   "metadata": {
    "id": "wo4k0ToJDa1q"
   },
   "source": [
    "Видим, что наилучшее качество получилось для модели с 12 факторами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wyiw5CGdJVjA",
   "metadata": {
    "id": "wyiw5CGdJVjA"
   },
   "source": [
    "#### Выводы:\n",
    "Если важна скорость решения задачи, то стоит использовать обычный SVD, он показывает достойное качество. \n",
    "\n",
    "NeuMF на данном датасете, без тчательного подбора параметров(количества и размеров слоёв, выбора функцй активаци и вероятности p в Dropout) и без выбора оптимально количество эпох(то есть не дожидаясь, пока ошибка выйдет на плато) показала сравнительно похожие результаты, даже немного похуже, но это вызвано лишь описанными выше особенностями. \n",
    "\n",
    "Гибридный подход, реализованный на базе NeuMF требует гораздо большего количества времени на обучение и подбор параметров. Было решено отдельно обучать дополнительные прзнаки и подъсоединять их уже в самом конце к остальной модели. Такой вариант имеет большую вычислительную сложность, так как становится на 1 нейронную сеть больше, но в перспективе это должно иметь лучшее качество при должном обучении и подборе параметров. В этой модели я совсем не старался получить хороший результат, потому что у меня закончился доступ к GPU, поэтому это стало практически нереализуемой задачей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bJwEd3qAJYcL",
   "metadata": {
    "id": "bJwEd3qAJYcL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
